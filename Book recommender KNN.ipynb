{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bcf1846-b116-4bb5-b94a-a8ffbbf948dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book title 'The Queen of the Damned (Vampire Chronicles (Paperback))' not found in dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load datasets with correct parameters\n",
    "books = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Books.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "ratings = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Ratings.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "users = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Users.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Rename columns for consistency\n",
    "books.rename(columns={\"ISBN\": \"ISBN\", \"Book-Title\": \"Title\", \"Book-Author\": \"Author\"}, inplace=True)\n",
    "ratings.rename(columns={\"User-ID\": \"UserID\", \"Book-Rating\": \"Rating\"}, inplace=True)\n",
    "users.rename(columns={\"User-ID\": \"UserID\"}, inplace=True)\n",
    "\n",
    "# Remove users with less than 200 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings = ratings[ratings['UserID'].isin(user_counts[user_counts >= 200].index)]\n",
    "\n",
    "# Remove books with less than 100 ratings\n",
    "book_counts = ratings['ISBN'].value_counts()\n",
    "ratings = ratings[ratings['ISBN'].isin(book_counts[book_counts >= 100].index)]\n",
    "\n",
    "# Merge datasets\n",
    "ratings = ratings.merge(books, on='ISBN')\n",
    "\n",
    "# Create pivot table\n",
    "book_pivot = ratings.pivot_table(index='Title', columns='UserID', values='Rating').fillna(0)\n",
    "book_sparse = csr_matrix(book_pivot.values)\n",
    "\n",
    "# Train KNN Model\n",
    "model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model.fit(book_sparse)\n",
    "\n",
    "def get_recommends(book_title):\n",
    "    if book_title not in book_pivot.index:\n",
    "        return f\"Book title '{book_title}' not found in dataset.\"\n",
    "    \n",
    "    book_index = book_pivot.index.get_loc(book_title)\n",
    "    distances, indices = model.kneighbors(book_pivot.iloc[book_index, :].values.reshape(1, -1), n_neighbors=6)\n",
    "    recommendations = [[book_pivot.index[i], float(distances[0][j])] for j, i in enumerate(indices[0]) if j != 0]\n",
    "    return [book_title, recommendations]\n",
    "\n",
    "# Example usage\n",
    "print(get_recommends(\"The Queen of the Damned (Vampire Chronicles (Paperback))\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f108eb56-818d-4c93-aa16-de4bbf7651b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book title 'The Hobbit' not found in dataset. Please try another title.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load datasets with correct parameters\n",
    "books = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Books.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "ratings = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Ratings.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "users = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Users.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Rename columns for consistency\n",
    "books.rename(columns={\"ISBN\": \"ISBN\", \"Book-Title\": \"Title\", \"Book-Author\": \"Author\"}, inplace=True)\n",
    "ratings.rename(columns={\"User-ID\": \"UserID\", \"Book-Rating\": \"Rating\"}, inplace=True)\n",
    "users.rename(columns={\"User-ID\": \"UserID\"}, inplace=True)\n",
    "\n",
    "# Remove users with less than 200 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings = ratings[ratings['UserID'].isin(user_counts[user_counts >= 200].index)]\n",
    "\n",
    "# Remove books with less than 100 ratings\n",
    "book_counts = ratings['ISBN'].value_counts()\n",
    "ratings = ratings[ratings['ISBN'].isin(book_counts[book_counts >= 100].index)]\n",
    "\n",
    "# Merge datasets\n",
    "ratings = ratings.merge(books, on='ISBN')\n",
    "\n",
    "# Create pivot table\n",
    "book_pivot = ratings.pivot_table(index='Title', columns='UserID', values='Rating').fillna(0)\n",
    "book_sparse = csr_matrix(book_pivot.values)\n",
    "\n",
    "# Train KNN Model\n",
    "model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model.fit(book_sparse)\n",
    "\n",
    "def get_recommends(book_title):\n",
    "    if book_title not in book_pivot.index:\n",
    "        return f\"Book title '{book_title}' not found in dataset. Please try another title.\"\n",
    "    \n",
    "    book_index = book_pivot.index.get_loc(book_title)\n",
    "    distances, indices = model.kneighbors(book_pivot.iloc[book_index, :].values.reshape(1, -1), n_neighbors=6)\n",
    "    recommendations = [[book_pivot.index[i], float(distances[0][j])] for j, i in enumerate(indices[0]) if j != 0]\n",
    "    return [book_title, recommendations]\n",
    "\n",
    "# Example usage\n",
    "print(get_recommends(\"The Hobbit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06814434-ec79-4a7a-a0b0-7a1996167a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book title 'Classical Mythology' not found in dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load datasets with correct parameters\n",
    "books = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Books.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "ratings = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Ratings.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "users = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Users.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Rename columns for consistency\n",
    "books.rename(columns={\"ISBN\": \"ISBN\", \"Book-Title\": \"Title\", \"Book-Author\": \"Author\"}, inplace=True)\n",
    "ratings.rename(columns={\"User-ID\": \"UserID\", \"Book-Rating\": \"Rating\"}, inplace=True)\n",
    "users.rename(columns={\"User-ID\": \"UserID\"}, inplace=True)\n",
    "\n",
    "# Remove users with less than 200 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings = ratings[ratings['UserID'].isin(user_counts[user_counts >= 200].index)]\n",
    "\n",
    "# Remove books with less than 100 ratings\n",
    "book_counts = ratings['ISBN'].value_counts()\n",
    "ratings = ratings[ratings['ISBN'].isin(book_counts[book_counts >= 100].index)]\n",
    "\n",
    "# Merge datasets\n",
    "ratings = ratings.merge(books, on='ISBN')\n",
    "\n",
    "# Create pivot table\n",
    "book_pivot = ratings.pivot_table(index='Title', columns='UserID', values='Rating').fillna(0)\n",
    "book_sparse = csr_matrix(book_pivot.values)\n",
    "\n",
    "# Train KNN Model\n",
    "model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model.fit(book_sparse)\n",
    "\n",
    "def get_recommends(book_title):\n",
    "    if book_title not in book_pivot.index:\n",
    "        return f\"Book title '{book_title}' not found in dataset.\"\n",
    "    \n",
    "    book_index = book_pivot.index.get_loc(book_title)\n",
    "    distances, indices = model.kneighbors(book_pivot.iloc[book_index, :].values.reshape(1, -1), n_neighbors=6)\n",
    "    recommendations = [[book_pivot.index[i], float(distances[0][j])] for j, i in enumerate(indices[0]) if j != 0]\n",
    "    return [book_title, recommendations]\n",
    "\n",
    "# Example usage\n",
    "print(get_recommends(\"Classical Mythology\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde7298c-f321-429e-8339-7efbb53df58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available books for recommendation:\n",
      "['1st to Die: A Novel', 'A Is for Alibi (Kinsey Millhone Mysteries (Paperback))', 'A Map of the World', 'A Painted House', 'A Prayer for Owen Meany', 'A Time to Kill', 'A Walk to Remember', 'All I Really Need to Know', 'Along Came a Spider (Alex Cross Novels)', 'Angels & Demons']\n",
      "['1st to Die: A Novel', [['Along Came a Spider (Alex Cross Novels)', 0.6923980317962177], ['Two for the Dough', 0.758241671664506], ['One for the Money (Stephanie Plum Novels (Paperback))', 0.7706038246057285], ['Three To Get Deadly : A Stephanie Plum Novel (A Stephanie Plum Novel)', 0.7839009208923955], ['Kiss the Girls', 0.7923405078589497]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load datasets with correct parameters\n",
    "books = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Books.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "ratings = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Ratings.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "users = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Users.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Rename columns for consistency\n",
    "books.rename(columns={\"ISBN\": \"ISBN\", \"Book-Title\": \"Title\", \"Book-Author\": \"Author\"}, inplace=True)\n",
    "ratings.rename(columns={\"User-ID\": \"UserID\", \"Book-Rating\": \"Rating\"}, inplace=True)\n",
    "users.rename(columns={\"User-ID\": \"UserID\"}, inplace=True)\n",
    "\n",
    "# Remove users with less than 200 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings = ratings[ratings['UserID'].isin(user_counts[user_counts >= 200].index)]\n",
    "\n",
    "# Remove books with less than 100 ratings\n",
    "book_counts = ratings['ISBN'].value_counts()\n",
    "ratings = ratings[ratings['ISBN'].isin(book_counts[book_counts >= 100].index)]\n",
    "\n",
    "# Merge datasets\n",
    "ratings = ratings.merge(books, on='ISBN')\n",
    "\n",
    "# Create pivot table\n",
    "book_pivot = ratings.pivot_table(index='Title', columns='UserID', values='Rating').fillna(0)\n",
    "book_sparse = csr_matrix(book_pivot.values)\n",
    "\n",
    "# Train KNN Model\n",
    "model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model.fit(book_sparse)\n",
    "\n",
    "def get_recommends(book_title):\n",
    "    if book_title not in book_pivot.index:\n",
    "        return f\"Book title '{book_title}' not found in dataset. Please try another title.\"\n",
    "    \n",
    "    book_index = book_pivot.index.get_loc(book_title)\n",
    "    distances, indices = model.kneighbors(book_pivot.iloc[book_index, :].values.reshape(1, -1), n_neighbors=6)\n",
    "    recommendations = [[book_pivot.index[i], float(distances[0][j])] for j, i in enumerate(indices[0]) if j != 0]\n",
    "    return [book_title, recommendations]\n",
    "\n",
    "# Example usage\n",
    "print(\"Available books for recommendation:\")\n",
    "print(book_pivot.index[:10].tolist())  # Show first 10 books for reference\n",
    "\n",
    "# Change the book title based on available options\n",
    "example_book = book_pivot.index[0]  # Pick the first book in the dataset as an example\n",
    "print(get_recommends(example_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8706586a-821b-464b-9a96-1c055ea44da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available books for recommendation:\n",
      "['1st to Die: A Novel', 'A Is for Alibi (Kinsey Millhone Mysteries (Paperback))', 'A Map of the World', 'A Painted House', 'A Prayer for Owen Meany', 'A Time to Kill', 'A Walk to Remember', 'All I Really Need to Know', 'Along Came a Spider (Alex Cross Novels)', 'Angels & Demons']\n",
      "['1st to Die: A Novel', [['Along Came a Spider (Alex Cross Novels)', 0.6923980317962177], ['Two for the Dough', 0.758241671664506], ['One for the Money (Stephanie Plum Novels (Paperback))', 0.7706038246057285], ['Three To Get Deadly : A Stephanie Plum Novel (A Stephanie Plum Novel)', 0.7839009208923955], ['Kiss the Girls', 0.7923405078589497]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load datasets with correct parameters\n",
    "books = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Books.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "ratings = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Ratings.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "users = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Users.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Rename columns for consistency\n",
    "books.rename(columns={\"ISBN\": \"ISBN\", \"Book-Title\": \"Title\", \"Book-Author\": \"Author\"}, inplace=True)\n",
    "ratings.rename(columns={\"User-ID\": \"UserID\", \"Book-Rating\": \"Rating\"}, inplace=True)\n",
    "users.rename(columns={\"User-ID\": \"UserID\"}, inplace=True)\n",
    "\n",
    "# Remove users with less than 200 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings = ratings[ratings['UserID'].isin(user_counts[user_counts >= 200].index)]\n",
    "\n",
    "# Remove books with less than 100 ratings\n",
    "book_counts = ratings['ISBN'].value_counts()\n",
    "ratings = ratings[ratings['ISBN'].isin(book_counts[book_counts >= 100].index)]\n",
    "\n",
    "# Merge datasets\n",
    "ratings = ratings.merge(books, on='ISBN')\n",
    "\n",
    "# Create pivot table\n",
    "book_pivot = ratings.pivot_table(index='Title', columns='UserID', values='Rating').fillna(0)\n",
    "book_sparse = csr_matrix(book_pivot.values)\n",
    "\n",
    "# Train KNN Model\n",
    "model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model.fit(book_sparse)\n",
    "\n",
    "def get_recommends(book_title):\n",
    "    if book_title not in book_pivot.index:\n",
    "        return f\"Book title '{book_title}' not found in dataset. Please try another title.\"\n",
    "    \n",
    "    book_index = book_pivot.index.get_loc(book_title)\n",
    "    distances, indices = model.kneighbors(book_pivot.iloc[book_index, :].values.reshape(1, -1), n_neighbors=6)\n",
    "    recommendations = [[book_pivot.index[i], float(distances[0][j])] for j, i in enumerate(indices[0]) if j != 0]\n",
    "    return [book_title, recommendations]\n",
    "\n",
    "# Example usage\n",
    "print(\"Available books for recommendation:\")\n",
    "print(book_pivot.index[:10].tolist())  # Show first 10 books for reference\n",
    "\n",
    "# Pick a book from the available dataset\n",
    "if len(book_pivot.index) > 0:\n",
    "    example_book = book_pivot.index[0]  # Pick the first available book in the dataset\n",
    "    print(get_recommends(example_book))\n",
    "else:\n",
    "    print(\"No books available for recommendation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1920232-a98e-4e13-a186-908b96a0efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book title 'The Queen of the Damned (Vampire Chronicles (Paperback))' not found in dataset. Please try another title.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load datasets with correct parameters\n",
    "books = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Books.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "ratings = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Ratings.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "users = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Users.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Rename columns for consistency\n",
    "books.rename(columns={\"ISBN\": \"ISBN\", \"Book-Title\": \"Title\", \"Book-Author\": \"Author\"}, inplace=True)\n",
    "ratings.rename(columns={\"User-ID\": \"UserID\", \"Book-Rating\": \"Rating\"}, inplace=True)\n",
    "users.rename(columns={\"User-ID\": \"UserID\"}, inplace=True)\n",
    "\n",
    "# Remove users with less than 200 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings = ratings[ratings['UserID'].isin(user_counts[user_counts >= 200].index)]\n",
    "\n",
    "# Remove books with less than 100 ratings\n",
    "book_counts = ratings['ISBN'].value_counts()\n",
    "ratings = ratings[ratings['ISBN'].isin(book_counts[book_counts >= 100].index)]\n",
    "\n",
    "# Merge datasets\n",
    "ratings = ratings.merge(books, on='ISBN')\n",
    "\n",
    "# Create pivot table\n",
    "book_pivot = ratings.pivot_table(index='Title', columns='UserID', values='Rating').fillna(0)\n",
    "book_sparse = csr_matrix(book_pivot.values)\n",
    "\n",
    "# Train KNN Model\n",
    "model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model.fit(book_sparse)\n",
    "\n",
    "def get_recommends(book_title):\n",
    "    if book_title not in book_pivot.index:\n",
    "        return f\"Book title '{book_title}' not found in dataset. Please try another title.\"\n",
    "    \n",
    "    book_index = book_pivot.index.get_loc(book_title)\n",
    "    distances, indices = model.kneighbors(book_pivot.iloc[book_index, :].values.reshape(1, -1), n_neighbors=6)\n",
    "    recommendations = [[book_pivot.index[i], float(distances[0][j])] for j, i in enumerate(indices[0]) if j != 0]\n",
    "    return [book_title, recommendations]\n",
    "\n",
    "# Example usage\n",
    "test_book = \"The Queen of the Damned (Vampire Chronicles (Paperback))\"\n",
    "result = get_recommends(test_book)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7551bb3-643f-4d5b-8878-0925476f4913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Lovely Bones: A Novel', [[\"Where the Heart Is (Oprah's Book Club (Paperback))\", 0.7234864549790632], [\"The Book of Ruth (Oprah's Book Club (Paperback))\", 0.7633429680750642], ['Good in Bed', 0.7659448088355895], [\"The Pilot's Wife : A Novel\", 0.767394675353033], ['Lucky : A Memoir', 0.7762122879349779]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load datasets with correct parameters\n",
    "books = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Books.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "ratings = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Ratings.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "users = pd.read_csv(r\"C:\\Users\\ranji\\OneDrive\\Desktop\\book-crossing dataset\\Users.csv\", sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Rename columns for consistency\n",
    "books.rename(columns={\"ISBN\": \"ISBN\", \"Book-Title\": \"Title\", \"Book-Author\": \"Author\"}, inplace=True)\n",
    "ratings.rename(columns={\"User-ID\": \"UserID\", \"Book-Rating\": \"Rating\"}, inplace=True)\n",
    "users.rename(columns={\"User-ID\": \"UserID\"}, inplace=True)\n",
    "\n",
    "# Remove users with less than 200 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings = ratings[ratings['UserID'].isin(user_counts[user_counts >= 200].index)]\n",
    "\n",
    "# Remove books with less than 100 ratings\n",
    "book_counts = ratings['ISBN'].value_counts()\n",
    "ratings = ratings[ratings['ISBN'].isin(book_counts[book_counts >= 100].index)]\n",
    "\n",
    "# Merge datasets\n",
    "ratings = ratings.merge(books, on='ISBN')\n",
    "\n",
    "# Create pivot table\n",
    "book_pivot = ratings.pivot_table(index='Title', columns='UserID', values='Rating').fillna(0)\n",
    "book_sparse = csr_matrix(book_pivot.values)\n",
    "\n",
    "# Train KNN Model\n",
    "model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model.fit(book_sparse)\n",
    "\n",
    "def get_recommends(book_title):\n",
    "    if book_title not in book_pivot.index:\n",
    "        return f\"Book title '{book_title}' not found in dataset. Please try another title.\"\n",
    "    \n",
    "    book_index = book_pivot.index.get_loc(book_title)\n",
    "    distances, indices = model.kneighbors(book_pivot.iloc[book_index, :].values.reshape(1, -1), n_neighbors=6)\n",
    "    recommendations = [[book_pivot.index[i], float(distances[0][j])] for j, i in enumerate(indices[0]) if j != 0]\n",
    "    return [book_title, recommendations]\n",
    "\n",
    "# Example usage\n",
    "test_book = \"The Lovely Bones: A Novel\"\n",
    "result = get_recommends(test_book)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89263885-5df9-4da9-9953-e15356294365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
